<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Machine Learning at Belle II</title>

		<meta name="description" content="An overview of Machine Learning">
		<meta name="author" content="Thomas Keck">

		<link rel="stylesheet" href="../reveal.js/css/reveal.css">
		<link rel="stylesheet" href="../reveal.mod/css/theme/black.css">
		<link rel="stylesheet" href="../reveal.js/lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? '../reveal.js/css/print/pdf.css' : '../reveal.js/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

    <style>
			.grid_element {
				display: inline-block;
				width: 40%;
				zoom: 1;         /* for IE */
				display*:inline; /* for IE */
			}
    </style>
	</head>
	<body>
		<div class="reveal">
			<div class="slides" style="height: 100%">
        <!-- Overview -->
				<section style="height: 100%">
				<section>
          <h1>Machine Learning: An Introduction</h1>

					<p>
          Thomas Keck (<a href="mailto:thomas.keck2@kit.edu">thomas.keck2@kit.edu</a>)
					</p>
        </section>
				
        <section>
          <h3>Japenese vs. Chinese</h3>

					<p class="fragment" style="font-size: 5em;">
		      电
					</p>
					
          <p class="fragment">
		      Chinese
					</p>
        </section>
        
        <section>
          <h3>Training / Fitting</h3>


          <p style="color: #9090f0;">
          Japanese (hiragana)
          </p>
					<p style="font-size: 2em;">
			    ま ち ね ら に ご
					</p>
          
          <p style="color: #f05050;">
          Chinese (kanji)
          </p>
					<p style="font-size: 2em;">
			    电 买 开 东 车 红 马
					</p>
        </section>

        <section>
          <h3>Application / Inference</h3>
          
					<div style="float: left; width: 50%">
          <p class="fragment" style="font-size: 2em;">
          の
          </p>
          <p class="fragment" style="color: #9090f0;">
          Japanese (hiragana)
          </p>
          <p class="fragment" style="font-size: 2em;">
          る
          </p>
          <p class="fragment" style="color: #9090f0;">
          Japanese (hiragana)
          </p>
          <p class="fragment" style="font-size: 2em;">
			    热
          </p>
          <p class="fragment" style="color: #f05050;">
          Chinese (kanji)
          </p>
          </div>
					<div style="float: right; width: 50%">
          <p class="fragment" style="font-size: 2em;">
			    时
          </p>
          <p class="fragment" style="color: #f05050;">
          Chinese (kanji)
          </p>
          <p class="fragment" style="font-size: 2em;">
			    な
          </p>
          <p class="fragment" style="color: #9090f0;">
          Japanese (hiragana)
          </p>
          <p class="fragment" style="font-size: 2em;">
			    陸
          </p>
          <p class="fragment" style="color: #f05050;">
          Chinese (kanji)
          </p>
          </div>
					
        </section>
		
        <section>
          <div style="margin-top: 20%"></div>
          <p>
          Take a moment to appreciate what you just did
          </p>
          <div style='height: 5vh'></div>
          <b>
          <p  class="fragment" style="color: #50f050;">
          Let's build a machine that can do this!
          </p>
          </b>
        </section>
		
        <section>

          <table>
            <tr><td class="grid_element"><img src="images/go.jpg"></td>
                <td class="grid_element"><img src="images/higgs.png"></td></tr>
            <tr><td class="grid_element"><img src="images/stock.jpg"></td>
                <td class="grid_element"><img src="images/supermarkt.jpg"></td></tr>
          </table>
        </section>

				<section style="height: 100%">
				<h3>Workflow</h3>
              <div class="fig-container"
                   data-fig-id="workflow"
                   data-file="animations/workflow.html" style="width: 100%; height: 100%"></div>
				</section>
				
				<section style="height: 100%">
				<h3>Multivariate Classification</h3>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/dataset.html" style="width: 100%; height: 100%"></div>
				</section>
        </section>
				
				<section style="height: 100%">
				<section>
          <h2><div style='color: #9090f0'>Decision Tree</div> & <div style='color: #f05050'>Model Complexity</div></h2>
				</section>
        <section style="height: 100%">
          <h3><div style='color: #9090f0'>Decision Tree (Inference)</div></h3>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/decision_tree.html" style="width: 100%; height: 100%"></div>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: #9090f0'>Decision Tree (Fitting)</div></h3>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/decision_tree_fitting.html" style="width: 100%; height: 100%"></div>
				</section>
        
        <section>
          <h3><div style='color: #9090f0'>Decision Tree (Summary)</div></h3>
          <div style="display: flex">
          <div style="width: 40%; height: 40vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Classifies using a number of consecutive rectangular cuts</li>
            <li>Each cut locally maximizes a separation gain measure</li>
            <li>Signal probability given by the purity in each leaf</li>
            <li>Interpretable (white box) model</li>
          </ul>
          </div>
          <div style="width: 60%; height: 40vh; float: right">
            <img data-src="images/tree_classifier.png" style="background:none; border:none; box-shadow:none;">
            Misclassification Rate: 16%
          </div>
          </div>

          <div style='height: 10vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import tree
            dt = tree.DecisionTreeClassifier(max_depth=4)
            dt.fit(X, y)
            dt.predict(X)
          </code></pre>
				</section>
        
				<section data-background-image="images/tree_visualization_30.png" data-background-size="60%">
          <h3><div style='color: #f05050'>Model Complexity</div></h3>
          <div style="width: 50%; height: 50vh; float: left" class="fragment">
            <div style="color: #50f050">Training Dataset</div><br />
            <img data-src="images/full_contour_train.png" style="background:#222; border:none; box-shadow:none;">
            Misclassification Rate: 0%
          </div>
          <div style="width: 50%; height: 50vh; float: right" class="fragment">
            <div style="color: #50f050">Independent Test Dataset</div><br />
            <img data-src="images/full_contour_test.png" style="background:#222; border:none; box-shadow:none;">
            Misclassification Rate: 21%
          </div>
				</section>
        
        <section>
          <h3><div style='color: #f05050'>Overfitting</div></h3>
          <ul style="font-size: 3vmin">
            <li>Model is too complex</li>
            <li>Statistical fluctuations in the training data dominate predictions</li>
            <li>Model does not generalize → poor performance on new data</li>
            <li>Need to check for this on an independent test dataset!</li>
          </ul>

          <center>
          <div style="width: 60%; height: 50vh">
            <img data-src="images/full_contour_test.png" style="background:none; border:none; box-shadow:none;">
          </div>
          </center>
				</section>
        
        <section>
          <h3><div style='color: #f05050'>Underfitting</div></h3>
          <ul style="font-size: 3vmin">
            <li>Model is too simple</li>
            <li>Relevant aspects of the data are ignored</li>
          </ul>

          <center>
          <div style="width: 60%; height: 50vh">
            <img data-src="images/simple_contour_test.png" style="background:none; border:none; box-shadow:none;">
          </div>
          </center>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: #9090f0'>Training vs. Test Error</div></h3>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/decision_tree_depth.html" style="width: 100%; height: 100%"></div>
				</section>
        
        <section>
          <h3><div style='color: #f05050'>Bias-Variance Dilemma</div></h3>
          <ul style="font-size: 3vmin">
            <li>Bias due to wrong modeling of the data (underfitting)</li>
            <li>Variance due to sensitivity to statistical fluctuations (overfitting)</li>
            <li>Irreducible error due to noise in the problem itself</li>
          </ul>
          <div style='height: 5vh'></div>
          $$ \mathrm{E} \left\lbrack (y- \widehat{f}(\vec{x}))^2 \right\rbrack = \mathrm{Bias} \left\lbrack \widehat{f}(\vec{x}) \right\rbrack^2 + \mathrm{Var} \left\lbrack \widehat{f}(\vec{x}) \right\rbrack + \mathrm{Var} \left\lbrack y \right\rbrack $$

          <div style="width: 100%; height: 30vh">
            <img data-src="images/bias_variance.png" style="background:none; border:none; box-shadow:none;">
          </div>
				</section>
        
        <section>
          <h3><div style='color: #f05050'>Model Complexity</div></h3>
          <b>Number of Degrees of freedom (NDF) of the model<br /> (≈ number of parameters)</b><br />

          <ul style="font-size: 3vmin">
            <li><div style='color: #50f050'>Input dataset</div></li>
            <ul>
              <li>Reduce dimensionality</li>
              <li>Higher statistic</li>
            </ul>
            <li><div style='color: #50f050'>Hyperparameters (control NDF)</div></li>
            <ul>
              <li>E.g. depth of the tree</li>
              <li>Optimized using search-algorithm</li>
            </ul>
            <li><div style='color: #50f050'>Regularization (reduce effective NDF)</div></li> 
            <ul>
              <li>E.g. Include tree structure in separation gain measure</li>
              <li>Ensemble methods</li>
            </ul>
          </ul>

				</section>
        
        <section>
          <h3><div style='color: #f05050'>Model Complexity</div> <br />(All you have to know)</h3>
				
          <div style="height: 10vh"></div>
          <b><div style="color: #50f050" class="fragment">Always test on an independent test dataset in the end!</div></b>

        </section>
        </section>
				
				<section style="height: 100%">
				<section>
          <h2><div style='color: #9090f0'>Boosted Decision Tree</div> & <div style='color: #f05050'>Ensemble Methods</div></h2>
				</section>
				
        <section>
          <h3><div style='color: #f05050'>Ensemble Methods</div></h2>

          <div style='height: 20vh'></div>
          <b>Average many simple models to obtain a robust complex model</b>
          <div style='height: 5vh'></div>
        
          $$ F\left( \vec{x} \right) = \sum_m \gamma_m f_m(\vec{x}) $$

				</section>
        
        <section style="height: 100%">
          <h3><div style='color: #f05050'>Boosting</div></h2>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/boosting.html" style="width: 100%; height: 100%"></div>
				</section>
        <section>
          <h3><div style='color: #f05050'>Boosting</div></h2>
          <div style="width: 35%; height: 50vh; float: left;">
            <img src="images/boosting_scheme.png" style="background:none; border:none; box-shadow:none;">
          </div>
          <div style="width: 65%; height: 50vh; float: right;">
            <div style="height: 5vh"></div>
            <ul style="font-size: 3vmin">
              <li>Reweight events w.r.t current prediction</li>
              <li>Individual classifiers are simple (weak-learners)</li>
              <li>Focus on events near the optimal separation hyper-plane</li>
              <li>Loss function L is crucial</li>
              <ul>
                <li>Least square → Regression</li>
                <li>Binomial deviance → GradientBoost Classification</li>
                <li>Exponential loss → AdaBoost classification</li>
              </ul>
            </ul>
          </div>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: #f05050'>Bagging</div></h2>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/bagging.html" style="width: 100%; height: 100%"></div>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: #f05050'>Bagging</div></h2>
          <div style="width: 100%; height: 20vh;">
            <img src="images/bagging_scheme.png" style="background:none; border:none; box-shadow:none;">
          </div>

            <div style="height: 5vh"></div>
            <ul style="font-size: 3vmin">
              <li>Use only a fraction of events / features per classifier</li>
              <li>Robustness against statistical fluctuations</li>
              <li>Embarrassingly parallel</li>
              <li>Sampling method is crucial:</li>
              <ul>
                <li><div style='color: #50f050; display: inline'>Bagging:</div> random events with replacements</li>
                <li><div style='color: #50f050; display: inline'>Pasting:</div> random events without replacement</li>
                <li><div style='color: #50f050; display: inline'>Random Subspaces:</div> random features</li>
              </ul>
            </ul>
				</section>
        
        <section>
          <h3><div style='color: #9090f0'>Stochastic Boosted Decision Tree (Summary)</div></h3>

          <div style="display: flex">
          <div style="width: 40%; height: 40vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Good out-of-the-box performance</li>
            <li>Robust against over-fitting</li>
            <li>Supports classification and regression</li>
            <li>Widely used in HEP</li>
          </ul>
          </div>
          <div style="width: 60%; height: 40vh; float:right">
            <img data-src="images/forest_classifier.png" style="background:none; border:none; box-shadow:none;">
            Misclassification Rate: 14.5%
          </div>
          </div>

          <div style='height: 10vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import ensemble
            bdt = ensemble.GradientBoostingClassifier(subsample=0.5,
                                                      max_depth=3,
                                                      n_estimators=50) 
            bdt.fit(X, y)
            bdt.predict(X)
          </code></pre>
				</section>
        
        <section>
          <h3><div style='color: #f05050'>Further Ensemble Methods</div></h2>

          <div style='height: 5vh'></div>
          <ul style="font-size: 3vmin">
            <center><b style='color: #50f050'>Categorization</b></center>
            <li>Divide feature-space into sub-spaces</li>
            <li>Different behavior of the data in the chosen subspaces</li>
            <li>e.g. train separate classifiers for Barrel and Endcap</li>
            <div style='height: 5vh'></div>
          
            <center><b style='color: #50f050'>Combination</b></center>
            <li>Combine different classifiers</li>
            <li>Different regularization methods learn different aspects of the data</li>
            <li>e.g. combine neural network, BDT and SVM</li>
          </ul>

				</section>

        </section>
				
        <section style="height: 100%">
				<section>
          <h2><div style='color: #9090f0'>Support Vector Machine</div> & <div style='color: #f05050'>Kernel Trick</div></h2>
				</section>
        <section>
          <h3><div style='color: #9090f0'>Support Vector Machine</div></h3>
          <div style="width: 50%; height: 50vh; float: left;" class="fragment">
            <img data-src="images/svm-hyperplane.png" style="background:none; border:none; box-shadow:none;"><br>
            <small><a href="https://en.wikipedia.org/wiki/Support_vector_machine#/media/File:Svm_max_sep_hyperplane_with_margin.png">Wikipedia</a></small>
          </div>
          <div style="width: 50%; height: 50vh; float: right;" class="fragment">
            <img data-src="images/linear_svm_classifier.png" style="background:none; border:none; box-shadow:none;">
            Misclassification Rate: 24%
          </div>
				</section>
				<section>
          <h3><div style='color: #f05050'>Kernel Trick</div></h3>
          <ul style="font-size: 3vmin">
            <li>SVM Algorithm depends only on scalar product!</li>
            <li>Replace scalar product with an arbitrary kernel function</li>
            <li>Solves problem in implicitly high-dimensional space</li>
          </ul>

          <div style='height: 5vh'></div>
          $$ \max g(c_1, \dots, c_n) $$
          $$ g(c_1, \dots, c_n)= \sum_i c_i - \frac{1}{2} \sum_i \sum_j y_i c_i (\vec{x}_i \cdot \vec{x}_j) y_j c_j$$
				</section>
        <section>
          <h3><div style='color: #f05050'>Kernel Trick</div></h3>
          <div style="width: 50%; height: 50vh; float: left;" class="fragment">
            <div style="color: #50f050">Polynomial Kernel<br /> $k(x_i, x_j) ) = (x_i \cdot x_j)^d$</div><br />
            <img data-src="images/poly_svm_classifier.png" style="background:none; border:none; box-shadow:none;">
            Misclassification Rate: 19%
          </div>
          <div style="width: 50%; height: 50vh; float: right;" class="fragment">
            <div style="color: #50f050">Gaussian Kernel<br /> $k(x_i, x_j) ) = \exp(-\gamma ||x_i \cdot x_j||^2)$</div><br />
            <img data-src="images/rbf_svm_classifier.png" style="background:none; border:none; box-shadow:none;">
            Misclassification Rate: 15%
          </div>
				</section>
        <section>
          <h3><div style='color: #9090f0'>Support Vector Machine (Summary)</div></h3>
          <div style="display: flex">
          <div style="width: 40%; height: 40vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Maximum margin classifier</li>
            <li>Quadratic problem: can be solved efficiently in $O(N^2)$</li>
            <li>Optimal for linearly separable problems</li>
            <li>Kernel trick allows solving of non-linear problems</li>
            <li>Solution depends only on the support-vectors</li>
          </ul>
          </div>
          <div style="width: 60%; height: 40vh; float:right">
            <img data-src="images/rbf_svm_classifier.png" style="background:none; border:none; box-shadow:none;">
            Misclassification Rate: 15%
          </div>
          </div>

          <div style='height: 10vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import svm
            svc = svm.SVC(kernel='rbf')
            svc.fit(X, y)
            svc.predict(X)
          </code></pre>
				</section>
        </section>
				
				<section style="height: 100%">
				<section>
          <h2><div style='color: #9090f0'>Artificial Neural Networks</div> & <div style='color: #f05050'>Stochastic Gradient Descent</div></h2>
				</section>

        <section style="height: 100%">
          <h3><div style='color: #9090f0'>Artificial Neural Network</div></h3>
              <div class="fig-container"
                   data-fig-id="neural_network"
                   data-file="animations/neural_network.html" style="width: 100%; height: 100%"></div>
        </section>
				
        <section  style="height: 100%">
          <h3><div style='color: #f05050'>Universal Function Approximator</div></h3>
  
          <div style='height: 2vh'></div>
          <div style='color: #50f050'>
          $$f(\vec{x}) = \sigma \left(\sum_h w_{oh} \sigma \left( \sum_i w_{hi} x_i \right) \right)$$
          </div>
          <div style='height: 1vh'></div>
          <b>→ can approximate any reasonable function $f: \mathrm{R}^\mathrm{N} \rightarrow [0, 1]$</b>
          <div style='height: 2vh'></div>

          Usually visualized as a network
          <div style="display: flex; height: 50%">
          <div style="width: 50%; float: left; height: 100%">
          <div style='height: 2vh'></div>
          <table>
            <tr><td>Link</td><td> $\hat{=}$</td><td>$w_{ij}$</td></tr>
            <tr><td>Neuron</td><td> $\hat{=}$</td><td>$\sigma \left( \sum \dots \right)$</td></tr>
          </table>
          </div>
          <div style="width: 50%; float: right; height: 100%">
          <div class="fig-container"
               data-fig-id="forward_neural_network"
               data-file="animations/forward_neural_network.html" style="width: 100%; height: 100%"></div>
          </div>
          </div>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: #f05050'>Backpropagation of Error</div></h3>
  
          <div style='height: 2vh'></div>
          <div style='color: #50f050'>
          $$ \Delta w  = - \eta \frac{\mathrm{d}\mathcal{L}}{\mathrm{d}w} $$
          </div>
          <div style='height: 1vh'></div>
          <b>→ choose weights so that they minimize a loss-function</b>
          <div style='height: 2vh'></div>

          <div style="display: flex; height: 50%">
          <div style="width: 55%; float: left; height: 100% ">
          <div style='height: 2vh'></div>
          <table>
            <tr><td>Classification</td><td>$ \mathcal{L} = H\left(y, f(\vec{x})\right) $</td></tr>
            <tr><td>Regression</td><td>$ \mathcal{L} = \left( y  - f(\vec{x}) \right)^2 $</td></tr>
          </table>
          </div>
          <div style="width: 45%; float: right; height: 100%">
          <div class="fig-container"
               data-fig-id="backward_neural_network"
               data-file="animations/backward_neural_network.html" style="width: 100%; height: 100%"></div>
          </div>
          </div>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: #f05050'>Stochastic Gradient Descent</div></h3>

          <ol style="font-size: 2.5vh">
            <li>Feed $N$ samples to the network ($N \hat{=} $ batch-size $\rightarrow$ <div style="color: #50f050; display: inline">stochastic</div>)</li>
            <li>Calculate the <div style="color: #50f050; display: inline">gradient</div> of the average loss with respect to each weight using the chain-rule of analysis</li>
            <li>Adjust the weights in the opposite direction (<div style="color: #50f050; display: inline">descent</div>) with a small step-size (learning-rate) $\eta$</li>
            <li>Repeat until convergence</li>
          </ol>
          
          <div class="fig-container"
               data-fig-id="sgd"
               data-file="animations/stochastic_gradient_descent.html" style="width: 100%; height: 60%"></div>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: #f05050'>Selected Aspects of Training</div></h3>
 
          <div style="display: flex; height: 50%">
          <div style="width: 50%; float: left; height: 100% ">
          <ul  style="font-size: 3vmin">
            <li style='color: #50f050' class="fragment" data-fragment-index="1">Stochastic gradient-descent</li>
            <ul class="fragment" data-fragment-index="1">
              <li>Batch-size and Learning rate</li>
              <li>Momentum term</li>
              <li>Second Order: Hesse Matrix (BFGS)</li>
            </ul>
            <li style='color: #50f050' class="fragment" data-fragment-index="2">Regularization</li>
            <ul  class="fragment" data-fragment-index="2">
              <li>Early stopping</li>
              <li>Weight decay: $\alpha \sum |w|^2$</li>
              <li>Dropout (ensemble)</li>
            </ul>
          </ul>
          </div>
          <div style="width: 50%; float: right; height: 100%">
          <ul  style="font-size: 3vmin">
            <li style='color: #50f050' class="fragment" data-fragment-index="3">Architecture</li>
            <ul class="fragment" data-fragment-index="3">
              <li>Number of neurons</li>
              <li>Number of layers</li>
              <li>Activation function</li>
              <li>Loss function</li>
            </ul>
            <li style='color: #50f050' class="fragment" data-fragment-index="4">Initialization</li>
            <ul class="fragment" data-fragment-index="4">
              <li>Distribution: Gaussian or Uniform</li>
              <li>Variance: Glorot, He</li>
            </ul>
          </ul>
          </div>
          </div>

          <div style='height: 10vh'></div>
          <p class="fragment" data-fragment-index="5" style='color: #f05050'>
          See Deep Learning Lecture
          </p>
				</section>
        
        <section>
          <h3><div style='color: #9090f0'>Artificial Neural Network (Summary)</div></h3>
          <div style="display: flex">
          <div style="width: 50%; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Universal function approximator</li>
            <li>Adjust weights to minimize loss-function</li>
            <li>Fast and small model</li>
            <li>Fitting can be challenging</li>
            <li>Ubiquitous in all modern ML applications</li>
          </ul>
          </div>
          <div style="width: 50%; float:right;">
            <img data-src="images/mpl_classifier.png" style="background:none; border:none; box-shadow:none;"><br/>
            Misclassification Rate: 15.5%
          </div>
          </div>

          <div style='height: 2vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import neural_network
            ann = neural_network.MLPClassifier(activation='tanh',
                                               hidden_layer_sizes=(3,))
            ann.fit(X, y)
            ann.predict(X)
          </code></pre>
				</section>
        </section>
				
				<section style="height: 100%">
				<section>
          <h2><div style='color: #9090f0'>Generative Models</div> & <div style='color: #f05050'>Neyman-Pearson Lemma</div></h2>
				</section>
        
        <section>
          <h3><div style='color: #f05050'>Neyman-Pearson Lemma</div></h3>
          
          <blockquote>
          On the Problem of the most Efficient Tests of Statistical Hypotheses
          <br>
          By J. Neyman and E. S. Pearson
          </blockquote>
          </pre>

          $$ f\left(\vec{x}\right) = \frac{\mathrm{PDF}\left( \vec{x} | \mathrm{S} \right)}{\mathrm{PDF}\left( \vec{x} | \mathrm{B} \right)} $$

          <p style='color: #50f050'>
          Most powerful test at a given significance level to distinguish between two simple hypotheses (signal or background)
          </p>
				</section>
        
        <section>
          <h3><div style='color: #f05050'>Problem solved? No!</div></h3>
          
          <p>
          Signal and Background PDF are usually unknown
          </p>

          <ul style="font-size: 3vmin">
            <li>High dimensional $\rightarrow$ cannot be sampled due to the <b>curse of dimensionality</b></li>
            <li>Multiple sources for signal and background</li>
            <li>Mislabelled training data / Simulation uncertainties</li>
          </ul>
         
          <img data-src="images/curse_of_dimensionality.png" style="background:none; border:none; box-shadow:none;">

				</section>
        
        <section>
          <h3><div style='color: #f05050'>Solution: Approximate Neyman-Pearson Lemma</div></h3>
          
          <div style="display: flex">
          <div style="width: 50%; height: 10vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li style="color: #50f050">Neyman-Pearson Lemma</li>
          </ul>
          </div>
          <div style="width: 50%; height: 10vh; float:right">
            $$ f\left(\vec{x}\right) = \frac{\mathrm{PDF}\left( \vec{x} | \mathrm{S} \right)}{\mathrm{PDF}\left( \vec{x} | \mathrm{B} \right)} $$
          </div>
          </div>
          
          <div style="display: flex">
          <div style="width: 50%; height: 20vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li style="color: #50f050">Generative Models</li>
            <ul style="font-size: 3vmin">
              <li>Analytical approx. (LDA, QDA)</li>
              <li>Kernel density estimator</li>
              <li>Gaussian mixture model</li>
            </ul>
          </ul>
          </div>
          <div style="width: 50%; height: 20vh; float:right">
            <div style="height: 5vh"></div>
            $$ f\left(\vec{x} | \mathrm{S}\right) \approx \mathrm{PDF}\left( \vec{x} | \mathrm{S} \right) $$
            $$ f\left(\vec{x} | \mathrm{B}\right) \approx \mathrm{PDF}\left( \vec{x} | \mathrm{B} \right) $$
          </div>
          </div>
          
          <div style="display: flex">
          <div style="width: 50%; height: 20vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li style="color: #50f050">Discriminative Models</li>
            <ul style="font-size: 3vmin">
              <li>(Boosted) Decision Trees</li>
              <li>Support Vector Machines</li>
              <li>Artificial Neural Networks</li>
            </ul>
          </ul>
          </div>
          <div style="width: 50%; height: 20vh; float:right">
            <div style="height: 5vh"></div>
            $$ f\left(\vec{x}\right) \approx \frac{\mathrm{PDF}\left( \vec{x} | \mathrm{S} \right)}{\mathrm{PDF}\left( \vec{x} | \mathrm{B} \right)} $$
          </div>
          </div>
          
				</section>
        
        <section>
          <h3><div style='color: #9090f0'>Linear Discriminant Analysis</div></h3>
          <div style="display: flex">
          <div style="width: 50%; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Assumes conditional PDFs are normally distributed</li>
            <li>Assumes identical covariances</li>
            <li>Equivalent to Fisher’s discriminant</li>
            <li>Requires only means and covariances of sample</li>
            <li>Separating hyperplane is linear</li>
            <br />
          $ f(x) = x^{\mathrm{T}} \cdot \Sigma^{-1} (\mu_{\mathrm{S}} - \mu_{\mathrm{B}}) $
          </ul>
          </div>
          <div style="width: 50%; float: right;">
            <img data-src="images/lda_classifier.png" style="background:none; border:none; box-shadow:none;"><br/>
            Misclassification Rate: 24%
          </div>
          </div>

          <div style='height: 2vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import lda
            ld = lda.LDA()
            ld.fit(X, y)
            ld.predict(X)
          </code></pre>
				</section>

        <section>
          <h3><div style='color: #9090f0'>Quadratic Discriminant Analysis</div></h3>
          <div style="display: flex">
          <div style="width: 50%; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Assumes conditional PDFs are normally distributed</li>
            <li>Requires only means and covariances of sample</li>
            <li>Separating hyperplane is quadratic</li>
          <p style="font-size: 2.5vmin">
          $ f(x) = \frac{\sqrt{2 \pi | \Sigma_{\mathrm{B}} |} \exp\left( - \frac{1}{2} \left(x - \mu_{\mathrm{S}}\right)^{\mathrm{T}} \Sigma^{-1}_{\mathrm{S}} \left(x - \mu_{\mathrm{S}}\right)  \right) }{ \sqrt{2 \pi | \Sigma_{\mathrm{S}} |}  \exp\left( - \frac{1}{2} \left(x - \mu_{\mathrm{B}}\right)^{\mathrm{T}} \Sigma^{-1}_{\mathrm{B}} \left(x - \mu_{\mathrm{B}}\right)  \right)  }$
          </p>
          </ul>
          </div>
          <div style="width: 50%; float:right">
            <img data-src="images/qda_classifier.png" style="background:none; border:none; box-shadow:none;"><br />
            Misclassification Rate: 21%
          </div>
          </div>

          <div style='height: 2vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import qda
            qd = qda.QDA()
            qd.fit(X, y)
            qd.predict(X)
          </code></pre>
				</section>
        
        <section>
          <h3><div style='color: #9090f0'>Kernel Density Estimator</div></h3>
          <div style="display: flex">
          <div style="width: 50%; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Every training sample is replaced with a small gaussian sphere</li>
            <li>Bandwith (variance of gaussian) is key</li>
            <li>Works well for low dimensions</li>
          <br />
          </ul>
          </div>
          <div style="width: 50%; height: 40vh; float:right">
            <img data-src="images/kde_classifier.png" style="background:none; border:none; box-shadow:none;">
            Misclassification Rate: 16%
          </div>
          </div>

          <div style='height: 2vh'></div>
          <b>SciPy Example</b>
          <pre><code class='python' data-trim>
            from scipy.stats import gaussian_kde
            signal = gaussian_kde(signal_samples)
            background = gaussian_kde(background_samples)
          </code></pre>
				</section>
        </section>
				
				<section style="height: 100%">
				<section>
          <h2><div style='color: #9090f0'>Extensions</div> & <div style='color: #f05050'>Multivariate Regression</div></h2>
				</section>
				<section style="height: 100%">
          <h3><div style='color: #9090f0'>(Generalized) Linear Regression</div></h3>
          <ul  style="font-size: 3vmin">
            <li>Linear Regression of Base-Functions</li>
            <li>$y = \beta_0 + \beta_1 \phi_1(x_1) + \dots \beta_n \phi_n(x_n)$</li>
            <li>Fitted with least-square method</li>
          </ul>
          
          <div style="width: 100%; height: 100%">
          <div class="fig-container"
               data-fig-id="linear_regression"
               data-file="animations/linear_regression.html" style="width: 100%; height: 100%"></div>
          </div>

				</section>
				
        <section style="height: 100%">
          <h3><div style='color: #9090f0'>(Boosted) Decision Trees</div></h3>
          <ul  style="font-size: 3vmin">
              <li>Various different algorithms exists</li>
              <li>Easiest: calculate average and right of each possible split points</li>
              <li>Minimize $\left(y - \bar{y}_{\mathrm{L}}\right)^2 + \left(y - \bar{y}_{\mathrm{R}}\right)^2$</li>
          </ul>
          
          <div style="width: 100%; height: 100%">
          <div class="fig-container"
               data-fig-id="decision_tree_regression"
               data-file="animations/decision_tree_regression.html" style="width: 100%; height: 100%"></div>
          </div>

				</section>
        
        <section style="height: 100%">
          <h3><div style='color: #9090f0'>Support Vector Regression</div></h3>
          <ul  style="font-size: 3vmin">
              <li>Search for maximum-margin hyper-band incorporating all data-points</li>
          </ul>
          
          <div style="width: 50%; height: 40vh; float: left;" class="fragment">
            <img data-src="images/svm-hyperplane.png" style="background:none; border:none; box-shadow:none; height: 70%"><br>
            <small><a href="https://en.wikipedia.org/wiki/Support_vector_machine#/media/File:Svm_max_sep_hyperplane_with_margin.png">Wikipedia</a></small>
          </div>
          <div style="width: 50%; height: 40vh; float: right;" class="fragment">
            <img data-src="images/svr.png" style="background:none; border:none; box-shadow:none; height: 70%"><br>
          <small style="width: 100%">
            <a href="https://www.researchgate.net/figure/Visualization-of-support-vector-regression-framework_fig1_272024714">
              M. Alamaniotis and V. Agarwal: Fuzzy Integration of Support Vector Regressor Models for Anticipatory Control of Complex Energy Systems
            </a>
          </small>
          </div>

				</section>
				
        <section>
          <h3><div style='color: #9090f0'>Artificial Neural Networks</div></h3>
          <ul>
            <li>Neural Networks are still <b>universal</b> function approximators</li>
            <li>Loss function: $\left(y - f(\vec{x})\right)^2$</li>
            <li>Output activation function: linear</li>
          </ul>
          
          <div style='height: 5vh'></div>
          <div style='color: #50f050'>
          $$f(\vec{x}) = \sum_h w_{oh} \sigma \left( \sum_i w_{hi} x_i \right)$$
          </div>
          <div style='height: 2vh'></div>
          <b>→ can approximate any reasonable function $f: \mathrm{R}^\mathrm{N} \rightarrow \mathrm{R}$</b>

				</section>
        
        <section>
          <h3><div style='color: #f05050'>Summary</div></h3>
          <div style='height: 10vh'></div>

          <p style='color: #50f050'>
          All concepts we encountered are still valid
          </p>
          <ul>
            <li>Model Complexity - Bias Variance Tradeoff</li>
            <li>Ensemble Methods - Boosting und Bagging</li>
            <li>SVM: Kernel Trick</li>
            <li>ANN: Stochastic Gradient Descent</li>
          </ul>

				</section>
        </section>
				
        <section style="height: 100%">
				<section>
          <h2><div style='color: #9090f0'>Outlook</div> & <div style='color: #f05050'>References</div></h2>
				</section>
				<section>
          <h3><div style='color: #9090f0'>Outlook</div></h3>

          <div style='height: 10vh'></div>
          There will be a second lecture on <div style='color: #50f050; display: inline'>Deep Learning</div> after a short break<br />
          <div style='height: 4vh'></div>
          There will be workshop on <div style='color: #50f050; display: inline'>Tensorflow</div> in the afternoon
				</section>
				<section data-markdown>
          <h3><div style='color: #f05050'>References</div></h3>

            <textarea data-template>
                An (incomplete) list of interesting books:

                  - Christopher M. Bishop. Pattern Recognition and Machine Learning
                  - Trevor Hastie, Robert Tibshirani, and Jerome Friedman. The Elements of Statistical Learning.
                  - J. Han, M. Kamber, J. Pei. Data Mining: Concepts and Techniques 
                  - O. Behnke, K. Kröninger, G. Scott, T. Schörner-Sadenius. Data Analysis in High Energy Physics: A Practical Guide to Statistical Methods
                  - [I. Goodfellow, Y. Bengio, A. Courville. Deep Learning (Adaptive Computation and Machine Learning)](http://www.deeplearningbook.org/)
                  - [R. S. Sutton, and A. G. Barto. Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book-2nd.html)


                You can find a list of research publications I enjoyed reading [here](https://thomaskeck.github.io/articles/)
            </textarea>
				</section>
        </section>
			</div>
		</div>

		<script src="../reveal.js/lib/js/head.min.js"></script>
		<script src="../reveal.js/js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
        controlsTutorial: false,
        center: false,
        transition: 'fade',
        history: true,
				dependencies: [
          { src: '../reveal.mod/js/d3.v4.min.js' },
          { src: '../reveal.mod/plugin/reveal.js-d3js-plugin/d3js.js' },
					{ src: '../reveal.js/plugin/markdown/marked.js' },
					{ src: '../reveal.js/plugin/markdown/markdown.js' },
					{ src: '../reveal.js/plugin/notes/notes.js', async: true },
					{ src: '../reveal.js/plugin/math/math.js', async: true },
					{ src: '../reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
