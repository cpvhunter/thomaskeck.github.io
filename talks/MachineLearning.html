<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Machine Learning at Belle II</title>

		<meta name="description" content="An overview of Machine Learning">
		<meta name="author" content="Thomas Keck">

		<link rel="stylesheet" href="../reveal.js/css/reveal.css">
		<link rel="stylesheet" href="../reveal.mod/css/theme/black.css">
		<link rel="stylesheet" href="../reveal.js/lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? '../reveal.js/css/print/pdf.css' : '../reveal.js/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

    <style>
			.grid_element {
				display: inline-block;
				width: 40%;
				zoom: 1;         /* for IE */
				display*:inline; /* for IE */
			}
    </style>
	</head>
	<body>
		<div class="reveal">
			<div class="slides" style="height: 100%">
        <!-- Overview -->
				<section style="height: 100%">
				<section>
          <h1>Machine Learning: An Introduction</h1>

					<p>
          Thomas Keck (<a href="mailto:thomas.keck2@kit.edu">thomas.keck2@kit.edu</a>)
					</p>
        </section>
				
        <section>
          <h3>Japenese vs. Chinese</h3>

					<p class="fragment" style="font-size: 5em;">
		      电
					</p>
					
          <p class="fragment">
		      Chinese
					</p>
        </section>
        
        <section>
          <h3>Training / Fitting</h3>


          <p style="color: #9090f0;">
          Japanese (hiragana)
          </p>
					<p style="font-size: 2em;">
			    ま ち ね ら に ご
					</p>
          
          <p style="color: #f05050;">
          Chinese (kanji)
          </p>
					<p style="font-size: 2em;">
			    电 买 开 东 车 红 马
					</p>
        </section>

        <section>
          <h3>Application / Inference</h3>
          
					<div style="float: left; width: 50%">
          <p class="fragment" style="font-size: 2em;">
          の
          </p>
          <p class="fragment" style="color: #9090f0;">
          Japanese (hiragana)
          </p>
          <p class="fragment" style="font-size: 2em;">
          る
          </p>
          <p class="fragment" style="color: #9090f0;">
          Japanese (hiragana)
          </p>
          <p class="fragment" style="font-size: 2em;">
			    热
          </p>
          <p class="fragment" style="color: #f05050;">
          Chinese (kanji)
          </p>
          </div>
					<div style="float: right; width: 50%">
          <p class="fragment" style="font-size: 2em;">
			    时
          </p>
          <p class="fragment" style="color: #f05050;">
          Chinese (kanji)
          </p>
          <p class="fragment" style="font-size: 2em;">
			    な
          </p>
          <p class="fragment" style="color: #9090f0;">
          Japanese (hiragana)
          </p>
          <p class="fragment" style="font-size: 2em;">
			    陸
          </p>
          <p class="fragment" style="color: #f05050;">
          Chinese (kanji)
          </p>
          </div>
					
        </section>
		
        <section>
          <div style="margin-top: 20%"></div>
          <p>
          Take a moment to appreciate what you just did
          </p>
          <div style='height: 5vh'></div>
          <b>
          <p  class="fragment" style="color: #50f050;">
          Let's build a machine that can do this!
          </p>
          </b>
        </section>
		
        <section>

          <table>
            <tr><td class="grid_element"><img src="images/go.jpg"></td>
                <td class="grid_element"><img src="images/higgs.png"></td></tr>
            <tr><td class="grid_element"><img src="images/stock.jpg"></td>
                <td class="grid_element"><img src="images/supermarkt.jpg"></td></tr>
          </table>
        </section>

				<section style="height: 100%">
				<h3>Workflow</h3>
              <div class="fig-container"
                   data-fig-id="workflow"
                   data-file="animations/workflow.html" style="width: 100%; height: 100%"></div>
				</section>
				
				<section style="height: 100%">
				<h3>Multivariate Classification</h3>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/dataset.html" style="width: 100%; height: 100%"></div>
				</section>
        </section>
				
				<section style="height: 100%">
				<section>
          <h2><div style='color: #9090f0'>Decision Tree</div> & <div style='color: #f05050'>Model Complexity</div></h2>
				</section>
        <section style="height: 100%">
          <h3><div style='color: #9090f0'>Decision Tree (Inference)</div></h3>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/decision_tree.html" style="width: 100%; height: 100%"></div>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: #9090f0'>Decision Tree (Fitting)</div></h3>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/decision_tree_fitting.html" style="width: 100%; height: 100%"></div>
				</section>
        
        <section>
          <h3><div style='color: #9090f0'>Decision Tree (Summary)</div></h3>
          <div style="display: flex">
          <div style="width: 40%; height: 40vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Classifies using a number of consecutive rectangular cuts</li>
            <li>Each cut locally maximizes a separation gain measure</li>
            <li>Signal probability given by the purity in each leaf</li>
            <li>Interpretable (white box) model</li>
          </ul>
          </div>
          <div style="width: 60%; height: 40vh; float: right">
            <img data-src="images/tree_classifier.png" style="background:none; border:none; box-shadow:none;">
            Misclassification Rate: 16%
          </div>
          </div>

          <div style='height: 10vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import tree
            dt = tree.DecisionTreeClassifier(max_depth=4)
            dt.fit(X, y)
            dt.predict(X)
          </code></pre>
				</section>
        
				<section data-background-image="images/tree_visualization_30.png" data-background-size="60%">
          <h3><div style='color: #f05050'>Model Complexity</div></h3>
          <div style="width: 50%; height: 50vh; float: left" class="fragment">
            <div style="color: #50f050">Training Dataset</div><br />
            <img data-src="images/full_contour_train.png" style="background:#222; border:none; box-shadow:none;">
            Misclassification Rate: 0%
          </div>
          <div style="width: 50%; height: 50vh; float: right" class="fragment">
            <div style="color: #50f050">Independent Test Dataset</div><br />
            <img data-src="images/full_contour_test.png" style="background:#222; border:none; box-shadow:none;">
            Misclassification Rate: 21%
          </div>
				</section>
        
        <section>
          <h3><div style='color: #f05050'>Overfitting</div></h3>
          <ul style="font-size: 3vmin">
            <li>Model is too complex</li>
            <li>Statistical fluctuations in the training data dominate predictions</li>
            <li>Model does not generalize → poor performance on new data</li>
            <li>Need to check for this on an independent test dataset!</li>
          </ul>

          <center>
          <div style="width: 60%; height: 50vh">
            <img data-src="images/full_contour_test.png" style="background:none; border:none; box-shadow:none;">
          </div>
          </center>
				</section>
        
        <section>
          <h3><div style='color: #f05050'>Underfitting</div></h3>
          <ul style="font-size: 3vmin">
            <li>Model is too simple</li>
            <li>Relevant aspects of the data are ignored</li>
          </ul>

          <center>
          <div style="width: 60%; height: 50vh">
            <img data-src="images/simple_contour_test.png" style="background:none; border:none; box-shadow:none;">
          </div>
          </center>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: #9090f0'>Training vs. Test Error</div></h3>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/decision_tree_depth.html" style="width: 100%; height: 100%"></div>
				</section>
        
        <section>
          <h3><div style='color: #f05050'>Bias-Variance Dilemma</div></h3>
          <ul style="font-size: 3vmin">
            <li>Bias due to wrong modeling of the data (underfitting)</li>
            <li>Variance due to sensitivity to statistical fluctuations (overfitting)</li>
            <li>Irreducible error due to noise in the problem itself</li>
          </ul>
          <div style='height: 5vh'></div>
          $$ \mathrm{E} \left\lbrack (y- \widehat{f}(\vec{x}))^2 \right\rbrack = \mathrm{Bias} \left\lbrack \widehat{f}(\vec{x}) \right\rbrack^2 + \mathrm{Var} \left\lbrack \widehat{f}(\vec{x}) \right\rbrack + \mathrm{Var} \left\lbrack y \right\rbrack $$

          <div style="width: 100%; height: 30vh">
            <img data-src="images/bias_variance.png" style="background:none; border:none; box-shadow:none;">
          </div>
				</section>
        
        <section>
          <h3><div style='color: #f05050'>Model Complexity</div></h3>
          <b>Number of Degrees of freedom (NDF) of the model<br /> (≈ number of parameters)</b><br />

          <ul style="font-size: 3vmin">
            <li><div style='color: #50f050'>Input dataset</div></li>
            <ul>
              <li>Reduce dimensionality</li>
              <li>Higher statistic</li>
            </ul>
            <li><div style='color: #50f050'>Hyperparameters (control NDF)</div></li>
            <ul>
              <li>E.g. depth of the tree</li>
              <li>Optimized using search-algorithm</li>
            </ul>
            <li><div style='color: #50f050'>Regularization (reduce effective NDF)</div></li> 
            <ul>
              <li>E.g. Include tree structure in separation gain measure</li>
              <li>Ensemble methods</li>
            </ul>
          </ul>

				</section>
        
        <section>
          <h3><div style='color: #f05050'>Model Complexity</div> <br />(All you have to know)</h3>
				
          <div style="height: 10vh"></div>
          <b><div style="color: #50f050" class="fragment">Always test on an independent test dataset in the end!</div></b>

        </section>
        </section>
				
				<section style="height: 100%">
				<section>
          <h2><div style='color: #9090f0'>Boosted Decision Tree</div> & <div style='color: #f05050'>Ensemble Methods</div></h2>
				</section>
				
        <section>
          <h3><div style='color: #f05050'>Ensemble Methods</div></h2>

          <div style='height: 20vh'></div>
          <b>Average many simple models to obtain a robust complex model</b>
          <div style='height: 5vh'></div>
        
          $$ F\left( \vec{x} \right) = \sum_m \gamma_m f_m(\vec{x}) $$

				</section>
        
        <section style="height: 100%">
          <h3><div style='color: #f05050'>Boosting</div></h2>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/boosting.html" style="width: 100%; height: 100%"></div>
				</section>
        <section>
          <h3><div style='color: #f05050'>Boosting</div></h2>
          <div style="width: 35%; height: 50vh; float: left;">
            <img src="images/boosting_scheme.png" style="background:none; border:none; box-shadow:none;">
          </div>
          <div style="width: 65%; height: 50vh; float: right;">
            <div style="height: 5vh"></div>
            <ul style="font-size: 3vmin">
              <li>Reweight events w.r.t current prediction</li>
              <li>Individual classifiers are simple (weak-learners)</li>
              <li>Focus on events near the optimal separation hyper-plane</li>
              <li>Loss function L is crucial</li>
              <ul>
                <li>Least square → Regression</li>
                <li>Binomial deviance → GradientBoost Classification</li>
                <li>Exponential loss → AdaBoost classification</li>
              </ul>
            </ul>
          </div>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: #f05050'>Bagging</div></h2>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/bagging.html" style="width: 100%; height: 100%"></div>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: #f05050'>Bagging</div></h2>
          <div style="width: 100%; height: 20vh;">
            <img src="images/bagging_scheme.png" style="background:none; border:none; box-shadow:none;">
          </div>

            <div style="height: 5vh"></div>
            <ul style="font-size: 3vmin">
              <li>Use only a fraction of events / features per classifier</li>
              <li>Robustness against statistical fluctuations</li>
              <li>Embarrassingly parallel</li>
              <li>Sampling method is crucial:</li>
              <ul>
                <li><div style='color: #50f050; display: inline'>Bagging:</div> random events with replacements</li>
                <li><div style='color: #50f050; display: inline'>Pasting:</div> random events without replacement</li>
                <li><div style='color: #50f050; display: inline'>Random Subspaces:</div> random features</li>
              </ul>
            </ul>
				</section>
        
        <section>
          <h3><div style='color: #9090f0'>Stochastic Boosted Decision Tree (Summary)</div></h3>

          <div style="display: flex">
          <div style="width: 40%; height: 40vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Good out-of-the-box performance</li>
            <li>Robust against over-fitting</li>
            <li>Supports classification and regression</li>
            <li>Widely used in HEP</li>
          </ul>
          </div>
          <div style="width: 60%; height: 40vh; float:right">
            <img data-src="images/forest_classifier.png" style="background:none; border:none; box-shadow:none;">
            Misclassification Rate: 14.5%
          </div>
          </div>

          <div style='height: 10vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import ensemble
            bdt = ensemble.GradientBoostingClassifier(subsample=0.5,
                                                      max_depth=3,
                                                      n_estimators=50) 
            bdt.fit(X, y)
            bdt.predict(X)
          </code></pre>
				</section>
        
        <section>
          <h3><div style='color: #f05050'>Further Ensemble Methods</div></h2>

          <div style='height: 5vh'></div>
          <ul style="font-size: 3vmin">
            <center><b style='color: #50f050'>Categorization</b></center>
            <li>Divide feature-space into sub-spaces</li>
            <li>Different behavior of the data in the chosen subspaces</li>
            <li>e.g. train separate classifiers for Barrel and Endcap</li>
            <div style='height: 5vh'></div>
          
            <center><b style='color: #50f050'>Combination</b></center>
            <li>Combine different classifiers</li>
            <li>Different regularization methods learn different aspects of the data</li>
            <li>e.g. combine neural network, BDT and SVM</li>
          </ul>

				</section>

        </section>
				
        <section style="height: 100%">
				<section>
          <h2><div style='color: #9090f0'>Support Vector Machine</div> & <div style='color: #f05050'>Kernel Trick</div></h2>
				</section>
        <section>
          <h3><div style='color: #9090f0'>Support Vector Machine</div></h3>
          <div style="width: 50%; height: 50vh; float: left;" class="fragment">
            <img data-src="images/svm-hyperplane.png" style="background:none; border:none; box-shadow:none;">
            <small><a href="https://en.wikipedia.org/wiki/Support_vector_machine#/media/File:Svm_max_sep_hyperplane_with_margin.png">Wikipedia</a></small>
          </div>
          <div style="width: 50%; height: 50vh; float: right;" class="fragment">
            <img data-src="images/linear_svm_classifier.png" style="background:none; border:none; box-shadow:none;">
            Misclassification Rate: 24%
          </div>
				</section>
				<section>
          <h3><div style='color: #f05050'>Kernel Trick</div></h3>
          <ul style="font-size: 3vmin">
            <li>SVM Algorithm depends only on scalar product!</li>
            <li>Replace scalar product with an arbitrary kernel function</li>
            <li>Solves problem in implicitly high-dimensional space</li>
          </ul>

          <div style='height: 5vh'></div>
          $$ \max g(c_1, \dots, c_n) $$
          $$ g(c_1, \dots, c_n)= \sum_i c_i - \frac{1}{2} \sum_i \sum_j y_i c_i (\vec{x}_i \cdot \vec{x}_j) y_j c_j$$
				</section>
        <section>
          <h3><div style='color: #f05050'>Kernel Trick</div></h3>
          <div style="width: 50%; height: 50vh; float: left;" class="fragment">
            <div style="color: #50f050">Polynomial Kernel<br /> $k(x_i, x_j) ) = (x_i \cdot x_j)^d$</div><br />
            <img data-src="images/poly_svm_classifier.png" style="background:none; border:none; box-shadow:none;">
            Misclassification Rate: 19%
          </div>
          <div style="width: 50%; height: 50vh; float: right;" class="fragment">
            <div style="color: #50f050">Gaussian Kernel<br /> $k(x_i, x_j) ) = \exp(-\gamma ||x_i \cdot x_j||^2)$</div><br />
            <img data-src="images/rbf_svm_classifier.png" style="background:none; border:none; box-shadow:none;">
            Misclassification Rate: 15%
          </div>
				</section>
        <section>
          <h3><div style='color: #9090f0'>Support Vector Machine (Summary)</div></h3>
          <div style="display: flex">
          <div style="width: 40%; height: 40vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Maximum margin classifier</li>
            <li>Quadratic problem: can be solved efficiently in $O(N^2)$</li>
            <li>Optimal for linearly separable problems</li>
            <li>Kernel trick allows solving of non-linear problems</li>
          </ul>
          </div>
          <div style="width: 60%; height: 40vh; float:right">
            <img data-src="images/rbf_svm_classifier.png" style="background:none; border:none; box-shadow:none;">
            Misclassification Rate: 15%
          </div>
          </div>

          <div style='height: 10vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import svm
            svc = svm.SVC(kernel='rbf')
            svc.fit(X, y)
            svc.predict(X)
          </code></pre>
				</section>
        </section>
				
				<section style="height: 100%">
				<section>
          <h2><div style='color: #9090f0'>Artificial Neural Networks</div> & <div style='color: #f05050'>Deep Learning</div></h2>
				</section>

        <section style="height: 100%">
          <h3><div style='color: #9090f0'>Artificial Neural Network</div></h3>
              <div class="fig-container"
                   data-fig-id="neural_network"
                   data-file="animations/neural_network.html" style="width: 100%; height: 100%"></div>
        </section>
				
        <section>
          <h3><div style='color: #f05050'>Theory</div></h3>
          <div style="height: 5vh"></div>
          <b>Universal Function Approximator</b><br />
  
          <b>→ can approximate any reasonable function $f: \mathrm{R}^\mathrm{N} \rightarrow [0, 1]$</b>

          <div style='height: 5vh'></div>
          $$f(\vec{x}) = \sigma \left(\sum_h w_{oh} \sigma \left( \sum_i w_{hi} x_i \right) \right)$$
          <div style='height: 5vh'></div>

          <div style="color: #50f050">Usually visualized as a network (think Feynman Diagrams!)</div>
          <table>
            <tr><td>Link</td><td> $\hat{=}$</td><td>$w_{ij}$</td></tr>
            <tr><td>Neuron</td><td> $\hat{=}$</td><td>$\sigma \left( \sum \dots \right)$</td></tr>
          </table>
          <div class="fig-container"
               data-fig-id="forward_neural_network"
               data-file="animations/forward_neural_network.html" style="width: 100%; height: 100%"></div>
				</section>
        
        <section>
          <h3><div style='color: #f05050'>Theory</div></h3>
          <div style="height: 5vh"></div>
          <b>Backpropagation of Error</b><br />
  
          <b>Choose weights so that they minimize a loss-function</b>

          <div style='height: 5vh'></div>
          <table>
            <tr><td>Classification</td><td>$ \mathcal{L} = - y \log \left( f(\vec{x}) \right) - (1-y) \log \left(1 - f(\vec{x}) \right) $</td></tr>
            <tr><td>Regression</td><td>$ \mathcal{L} = \left( y  - f(\vec{x}) \right)^2 $</td></tr>
          </table>
          <div style='height: 5vh'></div>

          <div style="color: #50f050">Adapt weights of the network using the gradient</div>
          $$ \Delta w  = - \eta \frac{\mathrm{d}\mathcal{L}}{\mathrm{d}w} $$
          <div class="fig-container"
               data-fig-id="backward_neural_network"
               data-file="animations/backward_neural_network.html" style="width: 100%; height: 100%"></div>
				</section>
        
        <section>
          <h3><div style='color: #9090f0'>Artificial Neural Network (Summary)</div></h3>
          <div style="display: flex">
          <div style="width: 40%; height: 40vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Neurons sum up inputs and apply non-linear activation function</li>
            <li>The gradient of the loss-function adjusts the weights (back-propagation)</li>
            <li>Fast and small model</li>
            <li>Fitting can be challenging</li>
            <li>Ubiquitous in all modern ML applications</li>
          </ul>
          </div>
          </center>
          <div style="width: 60%; height: 40vh; float:right">
            <img data-src="images/mpl_classifier.png" style="background:none; border:none; box-shadow:none;">
            Misclassification Rate: 15.5%
          </div>
          </div>

          <div style='height: 10vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import neural_network
            ann = neural_network.MLPClassifier(activation='tanh', hidden_layer_sizes=(3,))
            ann.fit(X, y)
            ann.predict(X)
          </code></pre>
				</section>
        </section>
				
				<section style="height: 100%">
				<section>
          <h2><div style='color: #9090f0'>Analytical Solutions</div> & <div style='color: #f05050'>Neyman-Pearson Lemma</div></h2>
				</section>
        <section>
          <h3><div style='color: #9090f0'>Linear Discriminant Analysis (Summary)</div></h3>
          <div style="display: flex">
          <div style="width: 40%; height: 40vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Assumes conditional PDFs are normally distributed</li>
            <li>Assumes identical covariances of signal and background</li>
            <li>Equivalent to commonly used Fisher’s discriminant</li>
            <li>Requires only means and covariances of sample</li>
            <li>Separating hyperplane is linear</li>
          <br />
          $ f(x) = x^{\mathrm{T}} \cdot \Sigma^{-1} (\mu_{\mathrm{S}} - \mu_{\mathrm{B}}) $
          </ul>
          </div>
          </center>
          <div style="width: 60%; height: 40vh; float:right">
            <img data-src="images/lda_classifier.png" style="background:none; border:none; box-shadow:none;">
            Misclassification Rate: 24%
          </div>
          </center>
          </div>

          <div style='height: 10vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import lda
            ld = lda.LDA()
            ld.fit(X, y)
            ld.predict(X)
          </code></pre>
				</section>

        <section>
          <h3><div style='color: #9090f0'>Quadratic Discriminant Analysis (Summary)</div></h3>
          <div style="display: flex">
          <div style="width: 40%; height: 40vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Assumes conditional PDFs are normally distributed</li>
            <li>Requires only means and covariances of sample</li>
            <li>Separating hyperplane is quadratic</li>
          <br />
          $ f(x) = \frac{\sqrt{2 \pi | \Sigma_{\mathrm{B}} |} \exp\left( - \frac{1}{2} \left(x - \mu_{\mathrm{S}}\right)^{\mathrm{T}} \Sigma^{-1}_{\mathrm{S}} \left(x - \mu_{\mathrm{S}}\right)  \right) }{ \sqrt{2 \pi | \Sigma_{\mathrm{S}} |}  \exp\left( - \frac{1}{2} \left(x - \mu_{\mathrm{B}}\right)^{\mathrm{T}} \Sigma^{-1}_{\mathrm{B}} \left(x - \mu_{\mathrm{B}}\right)  \right)  }$
          </ul>
          </div>
          </center>
          <div style="width: 60%; height: 40vh; float:right">
            <img data-src="images/qda_classifier.png" style="background:none; border:none; box-shadow:none;">
            Misclassification Rate: 21%
          </div>
          </center>
          </div>

          <div style='height: 10vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import qda
            qd = qda.QDA()
            qd.fit(X, y)
            qd.predict(X)
          </code></pre>
				</section>
        </section>

				<section style="height: 100%">
				<section>
          <h2><div style='color: #9090f0'>Outlook</div> & <div style='color: #f05050'>References</div></h2>
				</section>
        </section>
			</div>
		</div>

		<script src="../reveal.js/lib/js/head.min.js"></script>
		<script src="../reveal.js/js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
        controlsTutorial: false,
        center: false,
        transition: 'fade',
        history: true,
				dependencies: [
          { src: '../reveal.mod/js/d3.v4.min.js' },
          { src: '../reveal.mod/plugin/reveal.js-d3js-plugin/d3js.js' },
					{ src: '../reveal.js/plugin/markdown/marked.js' },
					{ src: '../reveal.js/plugin/markdown/markdown.js' },
					{ src: '../reveal.js/plugin/notes/notes.js', async: true },
					{ src: '../reveal.js/plugin/math/math.js', async: true },
					{ src: '../reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
